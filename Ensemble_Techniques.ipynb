{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ensemble Learning***"
      ],
      "metadata": {
        "id": "VNIVzK5RykFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is Ensemble Learning in machine learning? Explain the key idea\n",
        "behind it.\n",
        "\n",
        "    ANS :- Ensemble learning is a theoretical framework in machine learning where multiple models often called \"weak learners\", are combined to form a stronger predictive system. The idea rests on the principle that diverse models capture different aspects of data, and their collective decision reduces variance, bias, and error. Techniques include bagging, boosting, and stacking, each differing in how models are trained and aggregated. Bagging emphasizes variance reduction, boosting focuses on bias correction, and stacking integrates heterogeneous learners.\n",
        "\n",
        "\n",
        "    # Key Idea Behind Ensemble Learning\n",
        "\n",
        "`Wisdom of Crowds`:-\n",
        "    \n",
        "  - Just like consulting multiple people yields better advice, combining models balances errors.\n",
        "\n",
        "`Error Reduction`:-\n",
        "\n",
        "- Bagging reduces variance.\n",
        "- Boosting reduces bias.\n",
        "- Stacking enhances generalization.\n",
        "\n",
        "`Diversity Principle`:-\n",
        "- Different models capture different aspects of data; their collective decision is more reliable."
      ],
      "metadata": {
        "id": "7A-9NKICyinS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What is the difference between Bagging and Boosting?\n",
        "\n",
        "    ANS :- Bagging trains models independently on random subsets, then aggregates results to reduce variance. Bagging emphasizes stability through parallel diversity\n",
        "    \n",
        "    Boosting trains models sequentially, each correcting prior errors, reducing bias. Boosting emphasizes accuracy through iterative refinement.\n",
        "    \n",
        "    Both are ensemble methods, but their theoretical distinction lies in variance reduction versus bias correction, reflecting complementary strategies for improving generalization."
      ],
      "metadata": {
        "id": "NrjZuEQL3DuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is bootstrap sampling and what role does it play in Bagging methods\n",
        "like Random Forest?\n",
        "\n",
        "    ANS  :- Bootstrap sampling is a statistical resampling technique where datasets are created by drawing observations with replacement from the original data. Each sample is the same size as the original but may repeat some points while omitting others.\n",
        "    \n",
        "    In Bagging methods like Random Forest, bootstrap sampling ensures each model (eX - decision tree) is trained on a slightly different dataset. This diversity reduces correlation among models, stabilizes predictions, and lowers variance.\n",
        "    \n",
        "    It injects randomness, enabling ensemble averaging to smooth fluctuations, making the combined predictor more robust and generalizable than any single tree trained on the full dataset.\n"
      ],
      "metadata": {
        "id": "V6JlvhPW5Wjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  What are Out-of-Bag (OOB) samples and how is OOB score used to\n",
        "evaluate ensemble models?\n",
        "\n",
        "    ANS :- Out-of-Bag (OOB) samples are the data points not selected in a bootstrap sample during bagging. Since each bootstrap sample is drawn with replacement, about one-third of the original dataset is left out. These excluded points form the OOB set.\n",
        "    \n",
        "    \n",
        "    The OOB score is computed by testing each model on its corresponding OOB samples, then aggregating results across the ensemble. Theoretically, this provides an unbiased estimate of generalization performance without needing a separate validation set. In Random Forests, OOB scoring acts as an internal cross-validation mechanism, ensuring efficiency and reliable evaluation of predictive accuracy.\n"
      ],
      "metadata": {
        "id": "Ta60PQOW6kZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compare feature importance analysis in a single Decision Tree vs. a\n",
        "Random Forest.\n",
        "\n",
        "    ANS :- In a single Decision Tree, feature importance is measured by how much each split reduces impurity (eX - Gini or entropy). Theoretical limitation: importance may be biased toward features with many levels and is unstable, since small data changes can alter the tree structure.\n",
        "  \n",
        "  \n",
        "    In a Random Forest, feature importance is averaged across many trees built on bootstrap samples and random feature subsets. This aggregation stabilizes importance values, reduces bias, and highlights consistently useful predictors. Theoretical strength: ensemble averaging provides more reliable, generalizable importance estimates compared to the variability of a single tree's analysis.\n"
      ],
      "metadata": {
        "id": "3Q_ZxT_o7XVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  Write a Python program to:\n",
        "- Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "- Train a Random Forest Classifier\n",
        "- Print the top 5 most important features based on feature importance scores."
      ],
      "metadata": {
        "id": "sCXBT8o49tTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance scores\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance and select top 5\n",
        "\n",
        "top_features = importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
        "\n",
        "# Print the top 5 features\n",
        "\n",
        "print(\"Top 5 most important features:\")\n",
        "print(top_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPj14E9Z-d_k",
        "outputId": "7b9f8ab2-e479-4b74-f61c-33fd7563c257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most important features:\n",
            "                 Feature  Importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Write a Python program to:\n",
        "- Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "- Evaluate its accuracy and compare with a single Decision Tree"
      ],
      "metadata": {
        "id": "NJLe13Po-5tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.3, random_state = 42\n",
        ")\n",
        "\n",
        "# Train a single Decision Tree\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state =42 )\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees\n",
        "\n",
        "bagging = BaggingClassifier(\n",
        "    estimator = DecisionTreeClassifier(),\n",
        "    n_estimators = 50,\n",
        "    random_state = 42\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Print results\n",
        "\n",
        "print(\"Accuracy of Single Decision Tree:\", dt_accuracy)\n",
        "print(\"Accuracy of Bagging Classifier:\", bagging_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRoT7wNi_CNe",
        "outputId": "10536124-fe2a-487b-b46f-478635e98963"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Single Decision Tree: 1.0\n",
            "Accuracy of Bagging Classifier: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Write a Python program to:\n",
        "- Train a Random Forest Classifier\n",
        "- Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "- Print the best parameters and final accuracy"
      ],
      "metadata": {
        "id": "1buLVpjK_-HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.3, random_state = 42\n",
        ")\n",
        "\n",
        "# Define the Random Forest model\n",
        "\n",
        "rf = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 3, 5, 10]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = rf,\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'accuracy'\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Final Accuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmQeZuv4_UH6",
        "outputId": "7a826da5-e93a-4d1f-b859-2ce4a1564452"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
            "Final Accuracy on Test Set: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python program to:\n",
        "- Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        "- Compare their Mean Squared Errors (MSE)"
      ],
      "metadata": {
        "id": "5Svi58ALBFfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.3, random_state = 42\n",
        ")\n",
        "\n",
        "# Train Bagging Regressor using Decision Trees\n",
        "\n",
        "bagging = BaggingRegressor(\n",
        "    estimator = DecisionTreeRegressor(),\n",
        "    n_estimators = 50,\n",
        "    random_state = 42,\n",
        "    n_jobs = -1\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging.predict(X_test)\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators = 100,\n",
        "    random_state = 42,\n",
        "    n_jobs = -1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# Print results\n",
        "print(\"Mean Squared Error (Bagging Regressor):\", mse_bagging)\n",
        "print(\"Mean Squared Error (Random Forest Regressor):\", mse_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlKjdq9rAo0O",
        "outputId": "70872f6d-3690-413b-c2c7-4bff91c091e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Bagging Regressor): 0.25787382250585034\n",
            "Mean Squared Error (Random Forest Regressor): 0.25650512920799395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "- Choose between Bagging or Boosting\n",
        "- Handle overfitting\n",
        "- Select base models\n",
        "- Evaluate performance using cross-validation\n",
        "- Justify how ensemble learning improves decision-making in this real-world\n",
        "context."
      ],
      "metadata": {
        "id": "cMj0QT0yCiEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Understand the Problem and Data`:- Clearly define the objective (predicting loan default) and understand the characteristics of the customer demographic and transaction history data. This includes identifying target variable, feature types, and potential data quality issues.\n",
        "\n",
        "- `Data Preprocessing and Feature Engineering`:- Perform necessary data cleaning, handle missing values, encode categorical features, scale numerical features, and engineer new features that could be relevant for loan default prediction (e.g., debt-to-income ratio, transaction frequency).\n",
        "\n",
        "- `Choose Between Bagging or Boosting`:- Analyze the bias-variance trade-off for the loan default dataset. If the base models are likely to have high variance (e.g., deep decision trees), Bagging (like Random Forest) is preferred. If base models are high-bias, Boosting (like Gradient Boosting or XGBoost) might be more effective to reduce bias iteratively. Consider initial model performance and error analysis to guide this choice.\n",
        "\n",
        "- `Select Base Models`:- For Bagging, common base models include Decision Trees (e.g., in Random Forest). For Boosting, typically weak learners like shallow Decision Trees (stumps) are used. The choice depends on the specific ensemble method selected in the previous step and the nature of the data.\n",
        "\n",
        "- `Handle Overfitting`:- Implement strategies to combat overfitting: for Bagging, increase n_estimators, limit tree depth in base models, and use OOB samples for validation. For Boosting, use regularization techniques (learning_rate, n_estimators, max_depth), introduce subsampling (subsample), and apply early stopping based on cross-validation performance.\n",
        "\n",
        "- `Evaluate Performance Using Cross-Validation`:- Employ k-fold cross-validation to get a robust estimate of the model's generalization performance. Use appropriate metrics for imbalanced datasets common in loan default prediction, such as precision, recall, F1-score, ROC AUC, and AUPRC, rather than just accuracy.\n",
        "\n",
        "- `Justify Ensemble Learning for Loan Default`:- Explain how combining multiple models reduces the risk of relying on a single, potentially biased or high-variance model. Discuss how ensemble methods provide more stable, accurate, and robust predictions, leading to better risk assessment, improved lending decisions, and reduced financial losses for the institution.\n",
        "\n",
        "- `Final Task`:- Summarize the comprehensive approach to predicting loan default using ensemble learning, highlighting the benefits and strategic choices made at each step."
      ],
      "metadata": {
        "id": "8UoQpzUrEHt6"
      }
    }
  ]
}